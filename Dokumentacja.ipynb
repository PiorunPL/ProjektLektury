{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4512db5",
   "metadata": {},
   "source": [
    "<i> Projekt zespołowy, Podstawy reprezentacji i analizy danych, Informatyka Stosowana 2021Z/2022L, Politechnika Warszawska;</i>\n",
    "    \n",
    "<i>Data: 01.02.2022r.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d20659",
   "metadata": {},
   "source": [
    "# Rozpoznawanie autora utworu literackiego na podstawie treści utworu z wykorzystaniem worka słów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd6708",
   "metadata": {},
   "source": [
    "* Autorzy: Jakub Maciejewski, Michał Ziober, Maja Nagarnowicz, Miłosz Moroz\n",
    "* <a href=\"https://github.com/PiorunPL/ProjektLektury\" >Repozytorium projektu</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0bdf2b",
   "metadata": {},
   "source": [
    "## Cel projektu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd088e0",
   "metadata": {},
   "source": [
    "Celem projektu było stworzenie programu, który na podstawie wybranego fragmentu utworu literackiego rozpozna jego autora. \n",
    "\n",
    "Program jest w stanie oszacować pradopodobieństwo przynależności danego fragmentu tesktu do jednego z wybranych przez nas autorów:\n",
    " * Adam Mickiewicz\n",
    " * Juliusz Słowacki  \n",
    " * Krzysztof Kamil Baczyński  \n",
    " * Henryk Sienkiewicz   \n",
    " * Bolesław Prus  \n",
    " * Aleksander Fredro   \n",
    " * Maria Konopnicka\n",
    " * Jan Kochanowski   \n",
    " * Tadeusz Borowski   \n",
    " * Sofokles    \n",
    " * Stefan Żeromski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fea3b3",
   "metadata": {},
   "source": [
    "## Worek słów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af1fe7",
   "metadata": {},
   "source": [
    "Dla każdego z powyższych autorów wybraliśmy po kilka stworzonych przez niego utworów \n",
    "(<a href=\"https://wolnelektury.pl/\" >źródło utworów</a>, listę wybranych utworów można znaleźć w pliku `FileDownloader.ipynb` w  <a href=\"https://github.com/PiorunPL/ProjektLektury\" >naszym repozytorium</a>), a następnie na podstawie tych tekstów utworzyliśmy worek słów odpowiadający tym autorom (informacja o słowach, które wystąpiły w danych utworach autora oraz przyporządkowana im liczba wystąpień - suma dla wszystkich tekstów).\n",
    "\n",
    "Worki te można znaleźc w katalogu `/Bags`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cfcb67",
   "metadata": {},
   "source": [
    "## Dopasowywanie fragmentu do autora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3767d7",
   "metadata": {},
   "source": [
    "Procedura dopasowania przekazanego fragmentu utworu literackiego do konkretnego autora:\n",
    "1. **Tworzymy worek słów dla podanego fragmentu utworu literackiego**\n",
    "2. **Analizujemy procentowe występowanie słów w danym fragmencie** - dla każdego słowa przyporządkowujemy jego częstość występowania w danym fragmencie\n",
    "(gdzie częstość wystąpienia to iloraz liczby wystąpień słowa w tekście i sumy wystąpień wszystkich słów w tekście)\n",
    "3. **Dla każdego słowa z worka słów poszczególnego autora obliczamy częstość jego wystąpienia**\n",
    "(gdzie częstość wystąpienia to iloraz liczby wystąpień słowa w wybranych utworach autora i sumy wystąpień wszystkich słów w utworach autora)\n",
    "4. **Liczymy odległości pomiędzy procentową częstością wystąpień słów w przekazanym fragmencie oraz częstością wystąpień tych samych słów we wszystkich wybranych tekstach danego autora**, gdzie odległość to wartość bezwględna z różnicy tych częstości dla danego słowa\n",
    "5. **Dla każdego autora sumujemy otrzymane odległości**\n",
    "6. **Na podstawie tych sum szacujemy prawdopodobieństwo przynależności danego fragmentu tekstu do jednego z autorów**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e60cdd",
   "metadata": {},
   "source": [
    "## Wykorzystane modele <a id='modele'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f4f1b2",
   "metadata": {},
   "source": [
    "W naszym projekcie wykorzystaliśmy kilka modeli wyznaczania najbardziej prawdopodobnego autora fragmentu. Poniżej przestawiamy ich konfigurację:\n",
    "\n",
    "* **Model pierwszy**:\n",
    "   -  Worki słów tworzone są dla każdego autora (a nie dla pojedynczej lektury)\n",
    "   -  Worki słów podlegają lematyzacji\n",
    "   -  Z worków słów usuwane są słowa stopu\n",
    "   \n",
    "   \n",
    "* **Model drugi**:\n",
    "   -  Worki słów tworzone są dla każdego autora (a nie dla pojedynczej lektury)\n",
    "   -  Worki słów podlegają lematyzacji\n",
    "   -  Z worków słów nie są usuwane słowa stopu\n",
    "   \n",
    "   \n",
    "* **Model trzeci**:\n",
    "   -  Worki słów tworzone są dla każdego autora (a nie dla pojedynczej lektury)\n",
    "   -  Worki słów nie podlegają lematyzacji\n",
    "   -  Z worków słów są usuwane słowa stopu\n",
    "   \n",
    "   \n",
    "* **Model czwarty**:\n",
    "   -  Worki słów tworzone są dla każdego autora (a nie dla pojedynczej lektury)\n",
    "   -  Worki słów nie podlegają lematyzacji\n",
    "   -  Z worków słów nie są usuwane słowa stopu\n",
    "   \n",
    "   \n",
    "* **Model piąty**:\n",
    "   -  Worki słów tworzone są dla każdego autora (a nie dla pojedynczej lektury)\n",
    "   -  Worki słów podlegają lematyzacji\n",
    "   -  W workach słów znajdują się **tylko** słowa stopu\n",
    "   \n",
    "   \n",
    "* **Model szósty**:\n",
    "   -  Worki słów tworzone są dla każdego autora (a nie dla pojedynczej lektury)\n",
    "   -  Worki słów nie podlegają lematyzacji\n",
    "   -  W worach słów znajdują się **tylko** słowa stopu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1c63a",
   "metadata": {},
   "source": [
    "## Struktura projektu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8595ce",
   "metadata": {},
   "source": [
    "Struktura plików w <a href=\"https://github.com/PiorunPL/ProjektLektury\" >naszym repozytorium</a>:\n",
    "\n",
    "* Foldery w repozytorium:\n",
    "\n",
    "    * `/Bags` - worki słów\n",
    "        * `/BagOfWords_noStopWords_Lemma` - worki słów bez uwzględnienia słów stopu, z lematyzacją\n",
    "        * `/BagOfWords_noStopWords_NotLemma` - worki słów bez uwzględnienia słów stopu, bez lematyzacji\n",
    "        * `/BagOfWords_onlyStopWords_Lemma` - worki słów uwzględniające tylko słowa stopu, z lematyzacją\n",
    "        * `/BagOfWords_onlyStopWords_NotLemma` - worki słów uwzględniające tylko słowa stopu, bez lematyzacji\n",
    "        * `/BagOfWords_withStopWords_Lemma` - worki słów z uwzględnienieniem słów stopu, z lematyzacją\n",
    "        * `/BagOfWords_withStopWords_NotLemma` - worki słów z uwzględnienieniem słów stopu, bez lematyzacji\n",
    "    * `/Fragments` - fragmenty z wybranych utworów literackich do testów; 108 fragmentów z 54 książek\n",
    "\n",
    "\n",
    "* Pliki w repozytorium\n",
    "\n",
    "    * `Dokumentacja.ipynb` - dokumentacja projektu\n",
    "    * `FileDownloader.ipynb` - skrypt do pobierania książek ze strony + spis wykorzystanych utworów\n",
    "    * `Measures.ipynb` - funkcje pomocnicze do obliczania odległości i najbardziej prawdopodobnych autorów fragmentu\n",
    "    * [Modele](#modele):\n",
    "        * `Model1.ipynb` - model pierwszy\n",
    "        * `Model2.ipynb` - model drugi\n",
    "        * `Model3.ipynb` - model trzeci\n",
    "        * `Model4.ipynb` - model czwarty\n",
    "        * `Model5.ipynb` - model piąty\n",
    "        * `Model6.ipynb` - model szósty\n",
    "    * `WordBag.ipynb` - funkcje pomocnicze do tworzenia worków słów oraz ich zapisu i odczytu z pliku + do lematyzacji\n",
    "    * `stopWords.txt` - lista słów stopu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc365a2",
   "metadata": {},
   "source": [
    "## Wykorzystane importy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349bfaff",
   "metadata": {},
   "source": [
    "#### SpaCy - do procesu lematyzacji wykorzystany został pakiet spacy. \n",
    "* <a href=\"https://spacy.io/\" >Link</a> do oficjalnej strony pakietu\n",
    "* <a href=\"http://gatak.pl/2020/12/27/spacy-po-polsku-lematyzacja/\" >Tutorial</a>, z którego skorzystaliśmy\n",
    "\n",
    "####  Ipynb - dzięki temu pakietowi mogliśmy stworzyć lepszą strukturę projektu, podzielić go na różne pliki\n",
    "* <a href=\"https://github.com/ipython/ipynb\" >Link</a> do repozytorium pakietu \n",
    "\n",
    "#### Inne, standardowe pakiety \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac10ac",
   "metadata": {},
   "source": [
    "## Analiza wyników i wnioski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f4aca",
   "metadata": {},
   "source": [
    "* **Najlepszym modelem okazał się być model trzeci - skuteczność ok. 80%** (worki słów nie podlegają lematyzacji, oraz są usuwane słowa stopu)\n",
    "\n",
    "* Niewiele gorszym modelem okazał się być **model pierwszy - sukteczność ok. 79.6%** (różniący się od modelu 3 wykorzystaniem lematyzacji). \n",
    "\n",
    "* **Najgorszym modelem okazał się być model piąty - skuteczność ok. 62%** (worki słów podlegają lematyzacji, znajdują się w nich tylko słowa stopu), co zgadza się z naszą intuicją. Słowa stopu są najmniej charakterystycznymi słowami pozwalającymi ocenić autora tekstu, są często stosowane przez wszystkich autorów jako nierozłączna część wielu zdań w języku polskim. \n",
    "\n",
    "* **Model szósty** (różniący się od modelu 5 tylko brakiem lematyzacji) miał identyczną skuteczność, model 5 miał jedynie większą sumę procentów poprawnych autorów. Możemy więc dojść do wniosku, że nasz program jest najmniej wiarygodny, gdy szacuje autora tekstu tylko i wyłączenie na podstawie słów stopu. Oba modele nie usuwają słów stopu, \n",
    "\n",
    "* **Modele drugi i czwarty osiągnęły taką samą skuteczność ok. 77.8%**, przy czym model 4 miał nieco większą sumę procentów poprawnych autorów.\n",
    "\n",
    "* Dla krótszych fragmentów szacowania programu są mniej dokładne. Czym dłuższy fragment tym zazwyczaj łatwiej dopasować autora danego fragmentu.\n",
    "* Dla modeli, które nie korzystają tylko ze słów stopu, często możemy zauważyć, że program oblicza duże prawdopobieństwo dla autora, który pisał o podobnej tematyce co oryginalny autor lub żył i tworzył w zbliżonym czasie."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
