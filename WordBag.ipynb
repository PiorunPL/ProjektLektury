{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ea3998",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m72\u001b[0m\n\u001b[1;33m    author = bag[0]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ważna uwaga:\n",
    "Pliki z lekturami (trzeba funkcji ustawić argument is_fragment=False) do wczytania muszą mieć następującą strukturę:\n",
    "Autor\n",
    "\n",
    "Tytuł(dowolna ilość linii)\n",
    "\n",
    "Ewentualny numer ISBN\n",
    "\n",
    "Tekst(dowolna ilość linii)\n",
    "Ewentualna stopka po treście(przypis od wolnychlektur): -----\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Przy podawaniu fragmentu(is_fragment=True) skanowany jest cały plik, więc struktura tekstu jest dowolna\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "tworzy worek słów z pliku\n",
    "file_name - nazwa pliku z której utworzyc worek słów; with_stop_words - True/False mówiący czy usuwać stop wordsy czy nie\n",
    "is_fragment - True/False - mówi czy podawany plik to fragment do sprawdzenia, czy cały utwór\n",
    "\"\"\"\n",
    "def create_bag_of_words_from_file(file_name, is_fragment, with_stop_words=False):\n",
    "#struktura worka: indeks to indeks, elementem jest lista ze słowem i liczebnością\n",
    "    bag = {}\n",
    "    stop_words = []\n",
    "#tablica znaków interpunkcyjnych do pozbycia się z wyrazów\n",
    "#TODO: jakieś jeszcze inne znaki?\n",
    "    punc = '''…!()-[]{};:'\"\\,<>./?@#$%^&*_~«—'''\n",
    "#ewentualne przypisanie stopwordsów\n",
    "    if not with_stop_words:\n",
    "        stop_words = get_stop_words_from_file('stopWords.txt')\n",
    "        \n",
    "    with open(file_name,'r', encoding='utf-8') as file:\n",
    "#autor\n",
    "        if not is_fragment:\n",
    "            bag[0] = get_author(file)\n",
    "            \n",
    "        for line in file:\n",
    "            for word in line.split():\n",
    "#jak dotrze do stopki-kończ\n",
    "                if not is_fragment and word == \"-----\":\n",
    "                    return bag\n",
    "                \n",
    "#usuwanie znaków interpunkcyjnych\n",
    "                for ele in word:\n",
    "                    if ele in punc:\n",
    "                        word = word.replace(ele, \"\")\n",
    "                word = word.lower()\n",
    "#jeśli jest stop wordsem- nie uwzględniamy (jeśli w funkcji było True, to 'stop_words' jest puste, czyli nie wejdzie do ifa)    \n",
    "                if word in stop_words:\n",
    "                    continue\n",
    "#dodawanie nowego słowa do worka, jeśli jeszcze go nie ma\n",
    "                if word not in bag and (len(word) != 0):\n",
    "                    bag[word] = 1\n",
    "#inkrementacja liczności słowa, jeśli już istnieje w worku\n",
    "                elif len(word) != 0:\n",
    "                    bag[word] += 1\n",
    "    return bag\n",
    "\n",
    "\"\"\"\n",
    "word_bags - lista stworzonych z lektur worków słów\n",
    "WAŻNE: w każdym worku pod indeksem 0(liczba, nie string) musi znajdować się autor danego utworu\n",
    "WAŻNE2: używać przed użyciem funkcji count_percents na workach\n",
    "struktura outputu: słownik, gdzie kluczem są autorzy, a wartościami worek słów(z których zostanie wyrzucony klucz 0-z autorem)\n",
    "\"\"\"\n",
    "#TODO: przetetować lepiej\n",
    "def combine_word_bags(word_bags):\n",
    "    combined = {}\n",
    "#przechodzenie po wszystkich workach z listy\n",
    "    for bag in word_bags:\n",
    "            keys = combined.keys()\n",
    "#pobieranie autora z aktualnego worka i usuwanie go ze słownika\n",
    "        author = bag[0]\n",
    "        del bag[0]\n",
    "#jeśli autor już jest w wynikowym worku, to aktualizujemy wystąpienia słów u niego\n",
    "        if author in keys:\n",
    "            for elem in bag:\n",
    "#jeśli autor ma już dane słowo, to dodajemy ilość wystąpień z aktualnie iterowanego worka\n",
    "                if elem in combined[author]:\n",
    "                    combined[author][elem] += bag[elem]\n",
    "#jeśli słowa jeszcze nie ma, to dodajemy rekord\n",
    "                else:\n",
    "                    combined[author][elem] = bag[elem]\n",
    "#jeśli autora nie ma jeszcze w wynikowym worku, to dodajemy rekord, przypisując do niego aktualny worek\n",
    "        else:\n",
    "            combined[author] = bag\n",
    "    return combined\n",
    "\n",
    "\"\"\"\n",
    "funkcja zmienia ilosć wystąpień danego słowa na procent wartość wystąpień w tekście\n",
    "\"\"\"\n",
    "def count_percents(word_bag):\n",
    "    amount = 0\n",
    "#zliczanie ilości słów w worku\n",
    "    for elem in word_bag:\n",
    "        if elem == 0:\n",
    "            continue\n",
    "        amount += word_bag[elem]\n",
    "#przeliczanie wystąpień na wartości procentowe\n",
    "    for elem in word_bag:\n",
    "        if elem == 0:\n",
    "            continue\n",
    "        word_bag[elem] = word_bag[elem]/amount*100\n",
    "    return word_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4521bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To są różne funkcje pomocnicze\n",
    "\"\"\"\n",
    "funkcja pobiera stop wordsy z pliku i zwraca je jako listę\n",
    "\"\"\"\n",
    "def get_stop_words_from_file(file_name):\n",
    "    stops = []\n",
    "    borders = [\"\\\\n\", \"'\"]\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            single_line = repr(line)\n",
    "            for char in borders:\n",
    "                single_line = single_line.replace(char,\"\")\n",
    "            if not(single_line == \"\"):\n",
    "                stops.append(single_line)\n",
    "    return stops\n",
    "\n",
    "\"\"\"\n",
    "funkcja pobiera autora utworu, przeskakuje tytuł i przeskakuje number ISBN\n",
    "\"\"\"\n",
    "def get_author(file):\n",
    "    author = file.readline()\n",
    "    author = author.replace(\"\\n\",\"\")\n",
    "    author = list(author)\n",
    "    if author[0] == \" \":\n",
    "        author[0] = \"\"\n",
    "    author = \"\".join(author)\n",
    "    \n",
    "    file.readline()\n",
    "    while not (file.readline()  == \"\\n\"):\n",
    "        continue\n",
    "    position_before = file.tell()\n",
    "    if not file.readline().startswith('ISBN'):\n",
    "        file.seek(position_before)\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a4937d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'testFile.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2bdfc42ada51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Do testów TODO: usunąć\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_bag_of_words_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'testFile.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mword_bags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mword_bags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-d9a29e86508a>\u001b[0m in \u001b[0;36mcreate_bag_of_words_from_file\u001b[1;34m(file_name, is_fragment, with_stop_words)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_stop_words_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopWords.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;31m#autor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_fragment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'testFile.txt'"
     ]
    }
   ],
   "source": [
    "#Do testów TODO: usunąć\n",
    "b = create_bag_of_words_from_file('testFile.txt', False)\n",
    "print(b)\n",
    "word_bags = []\n",
    "word_bags.append(b)\n",
    "combined = combine_word_bags(word_bags)\n",
    "#count_percents(b)\n",
    "#for i in (b.keys()):\n",
    "#    print(\"{0} : {1}\".format(i, b[i]))\n",
    "#combined = count_percents(combined)\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "709c296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51229f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
